# Improved Techniques for Trainning GANS

## 作者：Tim Salimans Ian Goodfellow Wojciech Zaremba Vicki Cheung Alec Radford Xi Chen 时间：2016

## 期刊/会议：NIPS

## 前言:

* 在文章的开篇，作者提出所关注的两个重点应用：半监督学习以及生成人类认为具有视觉真实感的图像。与大多数生成模型的工作不同，该文的主要目标不是训练一个能赋予测试数据高可能性的模型，也不要求模型在不使用任何标签的情况下能够很好地学习。

## 模型改进：

### 1 Feature matching

* 我们知道GAN中的判别器（discriminator，D）是用来判断输入到D中的样本是来自于真实数据还是生成器生成的数据，然后给出一个标量表示判别的结果，那么，如果将其作为一个分类器的话，类比于通常用卷积网络来分类的模型，我们就可以知道：D同样是从输入的真、假样本中进行特征提取的工作，然后通过比较真实的样本中的特征和生成样本中的特征差异来判断样本的来源。所以我们可以通过比较不同来源的样本在D的中间层所表示的特征差异来进一步的提高D判别的准确率，同时逼迫生成器G生成更好的更接近真实的样本。即可以不按照最初的方法（最大化D正确判别的概率）优化D，而是希望G生成的样本所表达的某些数据的统计值接近于D关注的真实样本中某些统计值。这样的话，如果它们足够接近的话，我们就可以认为生成样本所满足的分布接近真实数据分布假设f ( x ) 为D中间层输出的特征图，G的目标函数就变成了如下的形式：![image-20220108104845932](D:\workplace\note\数字水印论文\笔记\1月份\3号-9号\Improved Techniques for Trainning GANS_img\image-20220108104845932.png)

### 2 Minibatch discrimination

* 在GAN的训练过程中，经常会发生模式坍缩（mode collapse）的问题，此时G只会生成某些固定类别的样本，不能很好的接近真实数据所满足的分布。作者认为这个问题的出现是因为D每一次只单独的处理一个样本，它无法指出前后的生成样本之间的相似性，所以就无法给G提供有用的信息来使得G生成更多类型的样本。因此，我们可以每次给D一个小批次的样本，这样D就可以知道样本之间的差异性，从而使得G避免陷入模式坍缩的牢笼，图示化：

![在这里插入图片描述](D:\workplace\note\数字水印论文\笔记\1月份\3号-9号\Improved Techniques for Trainning GANS_img\20190508171916622.png)

### 3 Historical averaging

* 做historical averaging是防止模型的参数θ变化的太过于剧烈而不符合真实的情况，而参数的历史平均值可以在线更新，因此该学习规则可以很好地扩展到长时间序列。作者提出在生成网络和判别网络的损失函数中添加一个项：

![image-20220108111314042](D:\workplace\note\数字水印论文\笔记\1月份\3号-9号\Improved Techniques for Trainning GANS_img\image-20220108111314042.png)

* 公式中 θ[i]表示在i时刻的参数。这个项在网络训练过程中，也会更新。加入这个项后，梯度就不容易进入稳定的轨道，能够继续向均衡点更新。

### 4 One-side label smooth

* 这个方法是将分类器的判别结果0和1替换为平滑值：如0.9和0.1，这样做被证明可以降低神经网络对对抗样本的脆弱性。最优的判别函数分类器变为
* ![image-20220108112102369](D:\workplace\note\数字水印论文\笔记\1月份\3号-9号\Improved Techniques for Trainning GANS_img\image-20220108112102369.png)
* 也就是判别器的目标函数中正负样本的系数不再是0-1，而是α和β。在应用的时候将真实数据的正样本判别为0.9和生成数据的负样本设置为0.1既可。

### 5 Virtual batch normalization

* 我们知道DCGAN中使用了batch Normalization取得了不错的效果，但是BN所存在的一个问题：它会使得对于输入的x的输出高度依赖于其他输入的x'。因此作者提出，在每一个minibatch中的输入进行归一化时，只根据提前选出且在训练过程中不在改变的参考批次样本的统计信息进行操作，这样就避免了对于同一minibatch中其他输入样本的依赖。因为它的计算开销很大，因此一般只用在G中。

## 评估生成图像质量

​	生成式对抗网络GAN缺乏目标函数，使得不同模型的性能比较困难。所以该文提出两种评估图像生成质量的方法：

### Mechanical Turk (MTurk)

* 通过让人类注释器判断样本的视觉质量，可以获得一种直观的性能度量。选定一部分人，将真实图片和生成图片掺杂在一起，这些邀请人需要逐个指出给定图片是真实的还是生成的。但是使用人工注释器的一个缺点是，度量根据任务的设置和注释器的动机而变化。作者还发现，当我们对注释者的错误给予反馈时，结果发生了巨大的变化:通过从这些反馈中学习，注释者能够更好地指出生成图像中的缺陷，给出一个更悲观的质量评估。

### Inception score

* 作为人类注释器的替代方案，作者提出了一种评估样本的自动方法，发现它与人类评估很好地相关。作者认为好的样本（图像看起来像来自真实数据分布的图像）预计会产生：
  * 低熵：生成样本看起来很像从真实数据中采样得到
  * 高熵：生成样本的多样性应该很好



