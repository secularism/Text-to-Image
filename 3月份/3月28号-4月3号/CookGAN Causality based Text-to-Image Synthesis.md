# CookGAN: Causality based Text-to-Image Synthesis

## 作者：Bin Zhu、Chong-Wah Ngo

## 会议：2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)

## 为什么要提出CookGAN：

* 这篇论文从一个新的角度，即图像生成中的因果链，来解决文本到图像的合成问题。因果关系是烹饪中常见的现象。菜肴的外观取决于烹饪动作和配料。CookGAN模拟了因果链中的视觉效果，保留了细粒度的细节，并逐步上采样图像。
* 在此之前，网络多是强调图像质量，但是忽略了图像生成过程中的因果视觉场景。比如很难生成与“切鸡肉切成丁，拌烤花生”文本对应的图像。这是因为这句话是行动导向的。预期的图像细节是像“鸡丁”和“烤花生”这样的实体，以及搅拌这两个实体的视觉效果，以往的网络依赖于文本和视觉实体之间的映射，无法处理这种因果逼真的图像生成。该文研究的是菜谱-图像的合成，从烹饪菜谱中生成食物图像。与描述图像中所期望的视觉内容的视觉叙事句子不同，菜谱提供了作为实体的原料和烹饪步骤，从文字上指导菜肴的准备工作。

## CookGAN解决的问题：

1. 网络允许烹饪步骤和配料之间的明确互动
2. 进地学习菜肴在不同步骤中的演变，这样，即时修改食材和说明就有可能将菜肴的新效果可视化。
3. 成分作用的捆绑效应可以被建模。例如，鸡蛋的形状会根据动作是煮、煎还是蒸而变化。
4. 了解食材对菜肴的可见性和影响。例如，“糖”可能是看不见的，而“番茄酱”可以显著改变一道菜的外观
5. 当然除了上面的问题，CookGAN还考虑了照片和语义真实感图像的生成。逐步将图像从低分辨率提升到高分辨率。计算每个成分（ingredients，也就是食物原材料）对生成图像的子区域的相对重要性，以表示细粒度的成分细节。还可以使用现有的配料编码器对生成的食物图像的配料进行语义解释。

## CookGAN:

### 1.模型结构：

* ![image-20220330193026482](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220330193026482.png)

* CookGAN包含三对生成器和鉴别器。首先将嵌入的特征$\varphi_r$与高斯分布的随机噪声$Z$进行拼接，将结果输入上采样，上采样时一个多层前馈网络，将受扰动的特征转化为隐藏的图像特征$V_0$。CookGAN最关键的组件时Cooking Simulator（橘黄色区域）。

* 目标函数为：

  >$L=\sum_{i=0}^{2}L_{G_i}+\lambda L_{CA}$

  这里的$L_{G_i}$为第$i$个generator loss，$L_{CA}$是CA（StackGAN++中的条件作用增强）模块的loss，该损失被用作正则化器，以避免过拟合，并从配方嵌入流形中强制平滑采样。而$\lambda$参数是平衡这两种loss的权衡超参数。

### 2. Cooking Simulator：

* ![image-20220330210744451](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220330210744451.png)

* 该组件是模仿真实的烹饪场景，随着时间的推移，不同的切割和烹饪动作会组件施加在食材上。每一个动作都将一些成分转变成新的形式，改变成分、颜色或形状。比如，“胡萝卜”被切成片，“意大利面”与“鱿鱼酱”炒成黑色。接下来的后续操作可以沿着烹饪过程对表单进行附加更改。

* 图中$\varphi_{ing}$代表成分表，第$i$个尺度的图像特征表示为$V_i$，首先将图像特征$V_i$与成分特征表$\varphi_{ing}$进行融合，得到图像中各成分特征图的大小为$C \times L$。计算$F_{i_{attend}}$的第$j$个通道（图片中的蓝色区域表示为多个通道）为：

  > $F_{i_{attend_{j}}}=\sum_{m=0}^{M-1}\sigma(v_j^T \cdot f(\varphi_{ing_m}))f(\varphi_{ing_m})$

  这里的$f(\cdot)$是一个1x1的卷积，将成分特征映射到与第$i$个尺度的隐藏图像特征$V_i$相同的维度。通过$\sigma(\cdot)$（softmax函数）得到各成分的注意图。即$\sigma(v_j^T \cdot f(\varphi_{ing_m}))$。通过将图谱与相应的成分特征向量$f(\varphi_{ing_m})$相乘，来确定成分的空间位置。再对每个成分结果进行线性加权求和，得到第$j$个通道图像有成分特征图。

* 在此之后，用GRU对烹饪步骤进行顺序编码。在初始阶段使用$F_{i_{attend}}$，该设计的目的是模仿烹饪的过程（因为一步一步的将Instruction特征加进去，就像烹饪做菜一样，有步骤的把菜放入锅中），每一个烹饪的结果显然易见的是GRU的隐藏状态，这里将$\varphi_{ins}$表示为一个烹饪步骤序列。第$j$个通道GRU的最后一个隐藏状态表示为：

  > $F_{i_{cook_j}}=GRU(F_{i_{attend_j}},\varphi_{ins})$

  也就是说$F_{i_{attend}}$中的每个通道都需要与GRU和$\varphi_{ins}$进行编码。其中$F_{i_{cook_j}}$为第$i$个scale“cooked”特征图的第$j$个通道。最终cooked feature maps与$V_i$有相同的维数，然后将$V_i$、$F_{i_{attend}}$和$F_{i_{cook}}$三组feature map串联之后接入残差块中，然后得到的特征映射成为下一轮图像上采样的输入。

## 实验结果：

* ![image-20220330215153507](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220330215153507.png)
* ![image-20220330215253449](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220330215253449.png)
* 可以看到与基线相比，CookGAN的表现明显由于StackGAN++等其他方法。而在图三中可以看出，通过CookGAN模拟得到的图像与真实样本图像的成分组成模式类似，在制作不同食材时，更能模拟菜肴的颜色和纹理分布。

## 语义解释（Semantic Interpretation）：

作者认为，生成的图像不仅应该在视觉上吸引人，而且在语义上也应该可以解释，因此，设计了三个任务来衡量生成图像的可解释性。

### 任务1 Ingredient recognition（成分识别）：

* 成分识别是指对食品图像中的成分进行多重标注。
* ![image-20220331130803574](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220331130803574.png)
* 结果基本验证了CookGAN合成的图像与真实图像一样具有可解释性，上图列出了由CookGAN生成的两个示例图像的可识别成分，不仅可以辨认出可见的配料，也可以辨认出不可见的配料。结果与原始图像的结果基本一致。**但受解码器精度的限制，无论是真实图像还是合成图像，都无法区分“鸡肉”、“土豆”等成分。同样，饼干食谱中常见的“鸡蛋”和“小苏打”，在这两种图像中都被错误地检测出来。**

### 任务2 Image-to-recipe retrieval （I2R 图像到食谱的检索）：

* 这是一个反向工程任务，其中生成的图像被视为一个查询。作者们使用R2GAN来提取图像和菜谱的交叉模态特征。在实验结果这一节中的表的第三列可以看出CookGAN编码食物语义的能力优于StackGAN++，但是与使用原始图像作为查询相比，使用真实图像和合成图像进行检索之间仍然存在性能差距。

### 任务3 Image-to-image retrieval （I2I 图像到图像的检索）：

* 这个任务是使用生成的图像检索真实的食物图像。结果在实验结果这一节中的表的第四列。下图显示了由CookGAN生成的查询检索到的前5个图像。
* ![image-20220331132213512](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220331132213512.png)
* 检索到的图像不仅在视觉上相似，而且在语义上也相似。

## Content Manipulability（内容可操纵性）：

* CookGAN的一个优点是，可以通过对菜谱的增量操作事实生成图像，比如，通过语义更改配料列表（这点和Control GAN类似）
* ![image-20220331132524319](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220331132524319.png)
* 在上图中显示了添加“胡萝卜”，移除“胡萝卜”或使用“生菜”代替“胡罗卜”的例子。在添加的情况下可以看到胡萝卜（或橙色的东西）分布在整道菜中。而去掉胡萝卜，这道菜的橙色就会少很多，而令人印象深刻的是，CookGAN成功地掌握了菜肴中配料的可见性。
* ![image-20220331132841425](./CookGAN%20Causality%20based%20Text-to-Image%20Synthesis%EF%BC%9A_img/image-20220331132841425.png)
* 再上图a）中，添加“糖”，菜的外观没有多大变化，而b）展示了针对食材成分采用不同的烹饪方法所得到的图像，可以看到，鸡蛋的外观因为方法的改变而千差万别。

## 总结：

* CookGAN在T2I方法中提出了一个新颖的角度（R2GAN也是从菜谱生成图像，但是CookGAN是从因果关系出发，而R2GAN是从跨模态的角度出发）。但是CookGAN没有考虑配料的数量和烹饪风格（家常菜、糖醋）。

