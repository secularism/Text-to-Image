# Generative Adversarial Text to Image Synthesis

## 作者：Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran,Bernt Schiele, Honglak Lee 时间：2016

## 会议：ICML 

## 前言：

* 这篇文章介绍了一种能够将人工编写的一句描述性文本直接转换为图像。但是要解决这个具有挑战性的问题，需要解决两个子问题
  * 1.首先，学习一个文本特征表示，捕捉重要的视觉细节
  * 2.其次，利用这些功能来合成一个引人注目的图像，使得人们可能会误以为是真的。
* 对于上面两个子问题来说，当前的深度学习在自然语言表示和图像合成方面都取得了巨大的进展，但是作者又提出了另一个问题，仅靠深度学习还不能解决的一个难题：以文本描述为条件的图像分布是高度多模态的，也就是说，有很多看似合理的像素配置可以正确地说明描述。针对这一问题，作者提出生成式对抗网络对于条件多模态是一种非常自然的应用，因此该文的主要贡献是开发一个简单而有效的GAN架构和训练策略。

## 网络架构：

* ![image-20220303223744323](./Generative%20Adversarial%20Text%20to%20Image%20Synthesis_img/image-20220303223744323.png)
* 该架构是基于DCGAN进行的，可以很清楚的看到在输入方面，是有一个噪声向量和表达文字的向量作为网络的输入，然后用网络全连接层对文本向量压缩，最后得到128维向量，在原来的随机噪声后面直接相连（concate）输入生成网络中生成图片。
* 对于判别网络呢，作者也加入了这个文本描述。加入的方式是空间复制，就是对于N*N的feature map后面加其他模态信息的时候用的方法。在判别网络中，首先对输入做几个stride=2的卷积，每个卷积都带有spatial batch normalization和leaky Relu。当feature map的大小变为2x2时，则又一次对文本编码结果通过一个全连接层，将全连接层的结果拼接到这个大小为2x2的feature map上。然后对拼接结果做一个1x1的卷积和2x2的卷积。这篇论文判别器中加入文本信息，目的是的判别器要判别出文字描述与图片是否相符

## 判别器：

### GAN-CLS：

* 在文章中，作者提出为了使判别器能够拥有判断文本与图像是否匹配的能力，除了<假图，描述>，<真图，描述>外，添加了第三种样本<真图，不匹配描述>，前两种样本，可以生成合理的图像，后两种生成匹配描述，这样一来，判别器就能将是否合理图像和是否匹配的信号都传递给生成器了。![image-20220303225446582](./Generative%20Adversarial%20Text%20to%20Image%20Synthesis_img/image-20220303225446582.png)

### GAN-INT（基于流形插值的学习）：

* 流形学习的观点是认为，我们所能观察到的数据实际上是由一个低维流形映射到高维空间上的。因为在一些高维中的数据会产生维度上的冗余，实际上只需要比较低的维度就能唯一地表示。首先流形能够刻画数据的本质。就像深度学习“特征学习”，所谓特征，就是能“表示事物本质的内容”，一般来说特征的维度应该小于数据本身，跟我们卷积得到特征也是小于数据本身的。如果我们能够模拟低纬度生成高纬度这个生成过程，再通过对低维流形的微调，应该能得到对应的“有意义且有道理”的高维数据。
* ![image-20220303230232895](./Generative%20Adversarial%20Text%20to%20Image%20Synthesis_img/image-20220303230232895.png)
* 对于根据描述去生成图片的问题，文本描述数量相对较少是限制合成效果（多样性）的一个重要原因。所以，论文提出通过简单的插值方法来生成大量新的文本描述。这些插值得到的embedding是无法直接对应到人工文本标注上的，所以这一部分数据是不需要标注的。想要利用这些数据，只需要在生成器的目标函数上增加上面那一项。

## 实验结果：

* ![image-20220303230726144](./Generative%20Adversarial%20Text%20to%20Image%20Synthesis_img/image-20220303230726144.png)
* 从上面实验结果可以看出，GAN和GAN-CLS生成的图像与文本内容比较接近，但是图片真实度不够。而GAN-INT和GAN-INT-CLS生成的图片虽然看上去更真实，但是可能只匹配部分文本信息。在花的数据集上的效果方法看上去效果都比较好，可能是因为对于D来说，鸟的结构比较强，更容易判断出假的图片。